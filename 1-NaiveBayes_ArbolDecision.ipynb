{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecz8fhGgSSXO"
   },
   "source": [
    "# **Análisis de sentimiento-Naive Bayes + Árbol de decisión**\n",
    "### Proyecto minería de datos\n",
    "---\n",
    "##### Ela Katherine Shepherd Arévalo - Pablo Daurell Marina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-hybX9ziqWA",
    "outputId": "e65c47de-2ae4-4bfd-e3f3-77bdc14cf6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIlas3ueTvtw",
    "outputId": "32cf0160-c658-4cba-8bbd-1bdea7f2d4d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59iQE3Y_UplM",
    "outputId": "fd5ac082-12d9-45ed-899f-b2521c2ebe5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU9OJiCNRmM5"
   },
   "source": [
    "- Extraemos el dataset que usaremos, con 1.6 millones de tweets ([Sentiment140 dataset](https://www.kaggle.com/kazanova/sentiment140)). Quitamos las columnas que no necesitamos, como la fecha o el user que escribió el tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "2one3jHrTot4",
    "outputId": "1759e069-e3e3-403d-a8b3-41d8544db527"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:16 PDT 2009</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:17 PDT 2009</td>\n",
       "      <td>I just re-pierced my ears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:19 PDT 2009</td>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:19 PDT 2009</td>\n",
       "      <td>@octolinz16 It it counts, idk why I did either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:20:20 PDT 2009</td>\n",
       "      <td>@smarrison i would've been the first, but i di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment  ...                                               text\n",
       "0           0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1           0  ...  is upset that he can't update his Facebook by ...\n",
       "2           0  ...  @Kenichan I dived many times for the ball. Man...\n",
       "3           0  ...    my whole body feels itchy and like its on fire \n",
       "4           0  ...  @nationwideclass no, it's not behaving at all....\n",
       "5           0  ...                      @Kwesidei not the whole crew \n",
       "6           0  ...                                        Need a hug \n",
       "7           0  ...  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "8           0  ...               @Tatiana_K nope they didn't have it \n",
       "9           0  ...                          @twittera que me muera ? \n",
       "10          0  ...        spring break in plain city... it's snowing \n",
       "11          0  ...                         I just re-pierced my ears \n",
       "12          0  ...  @caregiving I couldn't bear to watch it.  And ...\n",
       "13          0  ...  @octolinz16 It it counts, idk why I did either...\n",
       "14          0  ...  @smarrison i would've been the first, but i di...\n",
       "\n",
       "[15 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"/content/drive/MyDrive/Mineria/sentiment140.csv\"\n",
    "data = pd.read_csv(file, encoding='latin', names=['sentiment','id','date','query','user','text'])\n",
    "data = data.drop(columns=['query', 'user', 'id'])\n",
    "data[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGxnHrQBR7be"
   },
   "source": [
    "#1. Preprocesado del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fysIzWbSCvCT"
   },
   "source": [
    "- Quitamos los links y menciones a otros usuarios de los tweets (con la forma *@usuario*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJptg-4fJvS5"
   },
   "outputs": [],
   "source": [
    "tweets_text = data['text']\n",
    "tweets_clean = []\n",
    "for tweet in tweets_text:\n",
    "  t= str.lower(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(www.\\S+)\", \" \", tweet))\n",
    "  tweets_clean.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rdbew62VVHEZ",
    "outputId": "2a333611-8952-4958-a361-416d35436cf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1    is upset that he can't update his Facebook by ...\n",
       "2    @Kenichan I dived many times for the ball. Man...\n",
       "3      my whole body feels itchy and like its on fire \n",
       "4    @nationwideclass no, it's not behaving at all....\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPt8seEgVG98",
    "outputId": "557d24c0-b8c1-48e1-e993-88f46db0051a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      awww  that s a bummer   you shoulda got david carr of third day to do it   d',\n",
       " 'is upset that he can t update his facebook by texting it    and might cry as a result  school today also  blah ',\n",
       " '  i dived many times for the ball  managed to save 50   the rest go out of bounds',\n",
       " 'my whole body feels itchy and like its on fire ',\n",
       " '  no  it s not behaving at all  i m mad  why am i here  because i can t see you all over there  ']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8ok_HhNndgM"
   },
   "source": [
    "- Comprobamos cuántos tweets con cada sentimiento hay: En este dataset, el valor 0 es para un sentimiento negativo, y 4 es para un sentimiento positivo. Para que quede más claro, usamos el 1 para indicar sentimiento positivo Hay 800000 tweets de cada clase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1HGoLjkk2hd",
    "outputId": "20945825-1803-437b-a443-5dd5942ce2fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_sentiment = data['sentiment'].replace(4, 1)\n",
    "tweets_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2vDzw7u6ePV"
   },
   "source": [
    "#2. Bag of words\n",
    "\n",
    "- Lo primero que haremos será probar el modelo de la bolsa de palabras, o “bag of words”, usando el algoritmo CountVectorizer de Scikit Learn\n",
    "- Este método tokenizará cada palabra y conviertirá cada tweet en un vector numérico con el número de ocurrencias de cada palabra. \n",
    "  - Para el tokenizador usamos la librería NLTK. Además, realizaremos varias pruebas, para ver la mejor forma de usar este modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqfcgWo4O_Bw"
   },
   "source": [
    "- En todas estas pruebas, existirá un factor común de preprocesamiento:\n",
    "> - En las stop words quitaremos las palabras que signalicen negación, como \"no\" y \"not\". Las stopwords son un conjunto de palabras, que, si se eliminan de una frase, no suelen quitarle el significado original.\n",
    "> - Hacemos una división de **train y test** de los datos, donde usamos un 70% de los datos para train y el 30% restante para test.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-kxqMe32qUz"
   },
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('nor')\n",
    "stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tEGaWImAvOn"
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(tweets_clean, tweets_sentiment, test_size=0.30, stratify=tweets_sentiment, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcvI7yqlx5sC"
   },
   "source": [
    "##2.1 Monogramas VS Bigramas\n",
    "\n",
    "- Cuando hablamos de n-gramas, un n-grama es una cadena de n palabras seguidas, y al definir este parámetro, indicamos el tamaño de n-grama que queremos incluir para el análisis. Los 1-gramas también se llaman monogramas; y los 2-gramas se llaman bigramas.\n",
    "  - Usando monogramas, cada elemento de la bolsa de palabras corresponderá con una palabra del vocabulario (En este caso solo nos centramos en la probabilidad de que aparezcan palabras sueltas)\n",
    "  - Usando bigramas, cada elemento corresponderá con dos palabras del vocabulario (En ese caso nos centramos, no solo en la probabilidad de que aparezca una palabra, si no también en la probabilidad de que aparezcan dos palabras juntas) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD9VOs5U5Nwb"
   },
   "source": [
    "- Vamos a hacer una comparación sobre el rango de los n-gramas que se van a extraer. Primero, solamente usaremos monogramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR8Gp9tbAvmK"
   },
   "outputs": [],
   "source": [
    "cv_vectorizer_11 = CountVectorizer(stop_words=stop_words,ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "cv_vector_traindata_11= cv_vectorizer_11.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mSaXnzX2qU3",
    "outputId": "8a2c58e8-f529-416a-f027-a4384e7e824e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, bag of words, train success rate: 80.18491071428572 %\n",
      "Multinomial Naive Bayes, bag of words, test success rate: 77.17625 %\n"
     ]
    }
   ],
   "source": [
    "cv_mnb_classifier = MultinomialNB()\n",
    "cv_mnb_classifier.fit(cv_vector_traindata_11, train_label)\n",
    "\n",
    "cv_vector_testdata_11 = cv_vectorizer_11.transform(test_data)\n",
    "cv_predictions_test_11 = cv_mnb_classifier.predict(cv_vector_testdata_11)\n",
    "cv_predictions_train_11 = cv_mnb_classifier.predict(cv_vector_traindata_11)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, bag of words, train success rate:\", np.mean(cv_predictions_train_11 == train_label)*100, \"%\")\n",
    "print(\"Multinomial Naive Bayes, bag of words, test success rate:\", np.mean(cv_predictions_test_11 == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjQBBfNB2qU5",
    "outputId": "842846b3-b86d-4933-a199-bd6375ce1577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.79      0.78    240000\n",
      "    positive       0.78      0.75      0.77    240000\n",
      "\n",
      "    accuracy                           0.77    480000\n",
      "   macro avg       0.77      0.77      0.77    480000\n",
      "weighted avg       0.77      0.77      0.77    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, cv_predictions_test_11, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-EJUuJr2rYX"
   },
   "source": [
    "--------------------------------------------------------------------------\n",
    "- En segundo lugar, probaremos a usar monogramas y bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tp6TkkEb2s0T"
   },
   "outputs": [],
   "source": [
    "cv_vectorizer_12 = CountVectorizer(stop_words=stop_words,ngram_range = (1,2),tokenizer = token.tokenize)\n",
    "cv_vector_traindata_12= cv_vectorizer_12.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFUTV0uf2s0U",
    "outputId": "86cb2748-f524-4eaf-82f3-fa465d24f9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, bag of words, train success rate: 91.73330357142856 %\n",
      "Multinomial Naive Bayes, bag of words, test success rate: 78.30437500000001 %\n"
     ]
    }
   ],
   "source": [
    "cv_mnb_classifier.fit(cv_vector_traindata_12, train_label)\n",
    "\n",
    "cv_vector_testdata_12 = cv_vectorizer_12.transform(test_data)\n",
    "cv_predictions_test_12 = cv_mnb_classifier.predict(cv_vector_testdata_12)\n",
    "cv_predictions_train_12 = cv_mnb_classifier.predict(cv_vector_traindata_12)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, bag of words, train success rate:\", np.mean(cv_predictions_train_12 == train_label)*100, \"%\")\n",
    "print(\"Multinomial Naive Bayes, bag of words, test success rate:\", np.mean(cv_predictions_test_12 == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_MHCr-72s0V",
    "outputId": "6be52974-16f5-43b0-8535-303c5ff5edd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.81      0.79    240000\n",
      "    positive       0.80      0.75      0.78    240000\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.78      0.78      0.78    480000\n",
      "weighted avg       0.78      0.78      0.78    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, cv_predictions_test_12, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nUr-pJJ3AGe"
   },
   "source": [
    "--------------------------------------------------------------------------------\n",
    "- Por último, probaremos estrictamente bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vH6okD66sV_"
   },
   "outputs": [],
   "source": [
    "cv_vectorizer_22 = CountVectorizer(stop_words=stop_words,ngram_range = (2,2),tokenizer = token.tokenize)\n",
    "cv_vector_traindata_22= cv_vectorizer_22.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qOUumtw6sWC",
    "outputId": "c22e7ab6-7a89-4e62-b5e4-af157a53e2a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, bag of words, train success rate: 93.11241071428572 %\n",
      "Multinomial Naive Bayes, bag of words, test success rate: 72.67166666666667 %\n"
     ]
    }
   ],
   "source": [
    "cv_mnb_classifier.fit(cv_vector_traindata_22, train_label)\n",
    "\n",
    "cv_vector_testdata_22 = cv_vectorizer_22.transform(test_data)\n",
    "cv_predictions_test_22 = cv_mnb_classifier.predict(cv_vector_testdata_22)\n",
    "cv_predictions_train_22 = cv_mnb_classifier.predict(cv_vector_traindata_22)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, bag of words, train success rate:\", np.mean(cv_predictions_train_22 == train_label)*100, \"%\")\n",
    "print(\"Multinomial Naive Bayes, bag of words, test success rate:\", np.mean(cv_predictions_test_22 == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DT46KE66sWD",
    "outputId": "82b6dafe-0719-40ce-a2c0-c071b217ad7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.80      0.75    240000\n",
      "    positive       0.77      0.65      0.71    240000\n",
      "\n",
      "    accuracy                           0.73    480000\n",
      "   macro avg       0.73      0.73      0.73    480000\n",
      "weighted avg       0.73      0.73      0.73    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, cv_predictions_test_22, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rkf1l1Ab8dbX"
   },
   "source": [
    "- Parece que la mejor opción es optar por un ngram_range = (1,2). Podemos ver que usar solamente bigramas es peor opción que las otras dos, porque sobreaprende en el train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3seJ5WWbx-mL"
   },
   "source": [
    "##2.2 Stemming Vs Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnheZsAgl4an"
   },
   "source": [
    "- A continuación, veremos qué preprocesado adicional será mejor. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Qe0Xpn3qKBG"
   },
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "lemmed_train = []\n",
    "stemmed_train = []\n",
    "lemmed_test = []\n",
    "stemmed_test = []\n",
    "\n",
    "for tweet in train_data:\n",
    "  lemmed_train.append(lem.lemmatize(tweet,\"v\"))\n",
    "  stemmed_train.append(stem.stem(tweet))\n",
    "\n",
    "for tweet in test_data:\n",
    "  lemmed_test.append(lem.lemmatize(tweet,\"v\"))\n",
    "  stemmed_test.append(stem.stem(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Wbwrhk1_nhM"
   },
   "source": [
    "- Primero probamos con la derivación/stemming, un proceso de normalización linguística donde una palabra se reduce a una raíz. La derivación ignora el contexto, y la raíz no tiene por qué ser una palabra real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7KtSS7Q9AVD"
   },
   "outputs": [],
   "source": [
    "cv_vector_traindata_stem= cv_vectorizer_12.fit_transform(stemmed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6I1aEw49AVG",
    "outputId": "b25830fd-2a9b-4744-8245-9b0985801757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, bag of words, train success rate: 91.75383928571429 %\n",
      "Multinomial Naive Bayes, bag of words, test success rate: 78.31375 %\n"
     ]
    }
   ],
   "source": [
    "cv_mnb_classifier.fit(cv_vector_traindata_stem, train_label)\n",
    "\n",
    "cv_vector_testdata_stem = cv_vectorizer_12.transform(stemmed_test)\n",
    "cv_predictions_test_stem = cv_mnb_classifier.predict(cv_vector_testdata_stem)\n",
    "cv_predictions_train_stem = cv_mnb_classifier.predict(cv_vector_traindata_stem)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, bag of words, train success rate:\", np.mean(cv_predictions_train_stem == train_label)*100, \"%\")\n",
    "print(\"Multinomial Naive Bayes, bag of words, test success rate:\", np.mean(cv_predictions_test_stem == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYnr0Bx09AVJ",
    "outputId": "f18bf52d-c4b6-45e7-aaa7-7b6f6d79eebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.81      0.79    240000\n",
      "    positive       0.80      0.75      0.78    240000\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.78      0.78      0.78    480000\n",
      "weighted avg       0.78      0.78      0.78    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, cv_predictions_test_stem, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NKJhFyhySJJ"
   },
   "source": [
    "-------------------------------------------------------------------------\n",
    "- Después probamos con la lematización, que reduce una palabra a su lema, que debe ser linguísticamente correcto. Además, la lematización tiene en cuenta el contexto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Bq_QaE0GcSg"
   },
   "outputs": [],
   "source": [
    "cv_vector_traindata_lem= cv_vectorizer_12.fit_transform(lemmed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0khWQO31GcSj",
    "outputId": "157ee404-8cfc-4541-fa16-38a06df00970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, bag of words, train success rate: 91.73330357142856 %\n",
      "Multinomial Naive Bayes, bag of words, test success rate: 78.30437500000001 %\n"
     ]
    }
   ],
   "source": [
    "cv_mnb_classifier.fit(cv_vector_traindata_lem, train_label)\n",
    "\n",
    "cv_vector_testdata_lem = cv_vectorizer_12.transform(lemmed_test)\n",
    "cv_predictions_test_lem = cv_mnb_classifier.predict(cv_vector_testdata_lem)\n",
    "cv_predictions_train_lem = cv_mnb_classifier.predict(cv_vector_traindata_lem)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, bag of words, train success rate:\", np.mean(cv_predictions_train_lem == train_label)*100, \"%\")\n",
    "print(\"Multinomial Naive Bayes, bag of words, test success rate:\", np.mean(cv_predictions_test_lem == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qryIOIeHGcSk",
    "outputId": "8f066dae-7ae7-4ea8-dcb4-c6ec9e5a4bd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.81      0.79    240000\n",
      "    positive       0.80      0.75      0.78    240000\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.78      0.78      0.78    480000\n",
      "weighted avg       0.78      0.78      0.78    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, cv_predictions_test_lem, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GjYJcXNAxXj"
   },
   "source": [
    "- Nos daría igual cuál elegir ya que la diferencia entre los resultados es mínima; elegimos la derivación para la siguiente fase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk2pKShjcCBP"
   },
   "source": [
    "##2.3 Tipos de Naive Bayes\n",
    "\n",
    "- Naive Bayes denomina una familia de clasificadores que simplifican la realidad, asumiendo que todas las variables o palabras utilizadas para clasificar son independientes (de ahí Naive = ingenuo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mhbeg0Pe-4R"
   },
   "source": [
    "- Lo que necesitamos por último, pues, es saber qué tipo de Naive Bayes deberíamos usar. Como anteriormente hemos estado usando Multinomial, los datos para él ya los tenemos: una tasa de aciertos del 91.753% en train y 78.313% en test\n",
    "\n",
    "- A continuación probaremos NB Bernoulli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-LVJyMHeFrz",
    "outputId": "f7bfb355-e8ae-4542-c484-cb8374d22d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes, bag of words, train success rate: 91.71258928571429 %\n",
      "Bernoulli Naive Bayes, bag of words, test success rate: 78.49708333333332 %\n"
     ]
    }
   ],
   "source": [
    "cv_b_classifier = BernoulliNB()\n",
    "cv_b_classifier.fit(cv_vector_traindata_stem, train_label)\n",
    "\n",
    "cv_predictions_train_b = cv_b_classifier.predict(cv_vector_traindata_stem)\n",
    "cv_predictions_test_b = cv_b_classifier.predict(cv_vector_testdata_stem)\n",
    "\n",
    "print(\"Bernoulli Naive Bayes, bag of words, train success rate:\", np.mean(cv_predictions_train_b == train_label)*100, \"%\")\n",
    "print(\"Bernoulli Naive Bayes, bag of words, test success rate:\", np.mean(cv_predictions_test_b == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4olihmpycYsD",
    "outputId": "7bd4d8ed-a1b8-4eb4-d302-50d133c8b12b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78    240000\n",
      "    positive       0.78      0.80      0.79    240000\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.79      0.78      0.78    480000\n",
      "weighted avg       0.79      0.78      0.78    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, cv_predictions_test_b, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X70cPNJf8oR3"
   },
   "source": [
    "--------------------------------------------------------------------------------\n",
    "- Por último, probaremos con \"Complement Naive Bayes\", un tipo de Naive Bayes que se especializa en datasets desequilibrados muy parecido al Multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBObO_Y68tg-",
    "outputId": "15fdc97c-d10e-47dc-d800-2cd2f54796bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement Naive Bayes, bag of words, train success rate: 91.75383928571429 %\n",
      "Complement Naive Bayes, bag of words, test success rate: 78.31375 %\n"
     ]
    }
   ],
   "source": [
    "cv_comp_classifier = ComplementNB()\n",
    "cv_comp_classifier.fit(cv_vector_traindata_stem, train_label)\n",
    "\n",
    "cv_predictions_test_comp = cv_comp_classifier.predict(cv_vector_testdata_stem)\n",
    "cv_predictions_train_comp = cv_comp_classifier.predict(cv_vector_traindata_stem)\n",
    "\n",
    "print(\"Complement Naive Bayes, bag of words, train success rate:\", np.mean(cv_predictions_train_comp == train_label)*100, \"%\")\n",
    "print(\"Complement Naive Bayes, bag of words, test success rate:\", np.mean(cv_predictions_test_comp == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMEy1_ta8tg_",
    "outputId": "8c8d5074-5cc0-4e3f-e12b-74a7907064b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.81      0.79    240000\n",
      "    positive       0.80      0.75      0.78    240000\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.78      0.78      0.78    480000\n",
      "weighted avg       0.78      0.78      0.78    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, cv_predictions_test_comp, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEyucq0k-GoO"
   },
   "source": [
    "- Parece que por poquísimo gana Bernoulli, pero ya que la diferencia es prácticamente nula, decidimos para el siguiente paso elegir Naive Bayes Multinomial, ya que es el usado normalmente en análisis de sentimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSxuTCNAfnLX"
   },
   "source": [
    "--------------------------------------------------------------------------------\n",
    "- Además de estas pruebas, intentamos probar el NBGaussiano, pero falló. Ya de por sí planteamos descartar usarlo, ya que es más útil para variables continuas/con distribución Gaussiana, y este no es el caso. Aún así, se probó, pero en la celda de LabelEncoding y Scaling, crasheó al usar toda la memoria RAM disponible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0ED8EnOo7vm"
   },
   "source": [
    "#3. TF-IDF\n",
    "\n",
    "- En este paso probaremos si usar TF-IDF presenta alguna mejora, ya que en principio aporta más información que CountVectorizer: \n",
    " - Seguimos teniendo una bolsa de palabras pero teniendo en cuenta no solo la cantidad de  apariciones de cada palabra en cada tweet, si no también la importancia de esta en el resto del corpus de datos.\n",
    "    \n",
    "- En vez de utilizar TfidfVectorizer, hemos elegido usar TfidfTransformer sobre la mejor salida obtenida de CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9erg9_0VGVN"
   },
   "outputs": [],
   "source": [
    "tfidfer = TfidfTransformer()\n",
    "tf_vector_traindata = tfidfer.fit_transform(cv_vector_traindata_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3wbC4_1Vt4d",
    "outputId": "71173d12-333a-4dd0-fdc9-6f688ccf8b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes, tf-idf, train success rate: 90.81678571428571 %\n",
      "Multinomial Naive Bayes, tf-idf, test success rate: 78.45854166666668 %\n"
     ]
    }
   ],
   "source": [
    "tf_mnb_classifier = MultinomialNB()\n",
    "tf_mnb_classifier.fit(tf_vector_traindata, train_label)\n",
    "\n",
    "tf_vector_testdata = tfidfer.transform(cv_vector_testdata_stem)\n",
    "tf_predictions_train = tf_mnb_classifier.predict(tf_vector_traindata)\n",
    "tf_predictions_test = tf_mnb_classifier.predict(tf_vector_testdata)\n",
    "\n",
    "print(\"Multinomial Naive Bayes, tf-idf, train success rate:\", np.mean(tf_predictions_train == train_label)*100, \"%\")\n",
    "print(\"Multinomial Naive Bayes, tf-idf, test success rate:\", np.mean(tf_predictions_test == test_label)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSpMyJao_nvH",
    "outputId": "c9d45535-fc3b-4eb0-81af-9956c3e6b708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.81      0.79    240000\n",
      "    positive       0.80      0.76      0.78    240000\n",
      "\n",
      "    accuracy                           0.78    480000\n",
      "   macro avg       0.79      0.78      0.78    480000\n",
      "weighted avg       0.79      0.78      0.78    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, tf_predictions_test, target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXJW5RHQ-phh"
   },
   "source": [
    "- Parece que ha bajado algo la tasa de éxitos en train, y, aunque apenas haya cambiado en test, esto es una mejora, ya que los porcentajes de acierto con un poco más parecidos, y TF-IDF ha conseguido que haya menos sobreaprendizaje en train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDVH4WCMNTYb"
   },
   "source": [
    "#4. Árbol de decisión\n",
    "\n",
    "- Los árboles de decisión son una técnica de aprendizaje supervisado que puede usarse en problemas de clasificación y de regresión. En estos árboles, cada nodo pregunta por el valor de una variable, y se crea un nuevo nivel de profundidad. Es necesario encontrar una profundidad óptima dl árbol para que haya buenos resultados sin sobreaprendizaje/\"overfitting\"\n",
    "\n",
    "- A continuación, hacemos un bucle donde se prueban distintas profundidades del árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVDiepip2Kzm",
    "outputId": "5db6b4eb-95c1-4412-ad86-dbd86dbc7b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "tree_train_acc = []\n",
    "tree_test_acc = []\n",
    "max_dep = np.arange(0, 30, 5)\n",
    "for i in max_dep[1:]:\n",
    "  print(i)\n",
    "  tree_classifier = DecisionTreeClassifier(criterion=\"gini\", max_depth=i)\n",
    "  tree_classifier.fit(tf_vector_traindata, train_label)\n",
    "  tree_predictions_train = tree_classifier.predict(tf_vector_traindata)\n",
    "  tree_predictions_test = tree_classifier.predict(tf_vector_testdata)\n",
    "  tree_train_acc.append(np.mean(tree_predictions_train == train_label))\n",
    "  tree_test_acc.append(np.mean(tree_predictions_test == test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayZrv97KKuDO",
    "outputId": "2ac4b2b5-beb4-4e24-e3c9-9949447f9cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "for i in [30, 35]:\n",
    "  print(i)\n",
    "  tree_classifier = DecisionTreeClassifier(criterion=\"gini\", max_depth=i)\n",
    "  tree_classifier.fit(tf_vector_traindata, train_label)\n",
    "  tree_predictions_train = tree_classifier.predict(tf_vector_traindata)\n",
    "  tree_predictions_test = tree_classifier.predict(tf_vector_testdata)\n",
    "  tree_train_acc.append(np.mean(tree_predictions_train == train_label))\n",
    "  tree_test_acc.append(np.mean(tree_predictions_test == test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2K_XWyOJLKeX"
   },
   "outputs": [],
   "source": [
    "max_dep = [5, 10, 15, 20, 25, 30, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "nfyMaOSkPYwC",
    "outputId": "0f456d84-6edd-43a2-e66a-ec34dd5ae88d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(max_dep, tree_train_acc, label=f\"Training\", color =\"r\")\n",
    "plt.plot(max_dep, tree_test_acc, label=f\"Test\", color = \"b\")\n",
    "\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seFiP7LsEM44"
   },
   "source": [
    "- Desgraciadamente, 35 era la profundidad máxima que pudimos analizar, ya que a partir de ese número Colab se congelaba y no pudimos continuar. Aun así, podemos ver que la tasa de aciertos de tanto train como test están muy igualadas hasta, aproximadamente, profundidad 15; pero a partir de ahí test mejora más lentamente que train, por tanto creemos que habría un punti donde la curva logarítmica de test dejaría de subir mucho, y por ese punto sería la profundidad óptima para el árbol.\n",
    "En el rango que hemos podido observar, la precisión más alta es de un 68%, lo cual es bastante peor que Bag of words y TF-IDF."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
